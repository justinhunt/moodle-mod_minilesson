{"version":3,"file":"ttmsspeech.min.js","sources":["../src/ttmsspeech.js"],"sourcesContent":["define(['jquery', \n    'core/log'], \n    function ($, log) {\n    \n   \"use strict\"; // jshint ;_;\n    /*\n    This file streams to msspeech and collects the response. \n     */\n\n    log.debug('MS Speech initialising');\n\n    return {\n\n        thetoken: null,\n        theregion: null,\n        thelanguage: null,\n        thereferencetext: null,\n        speechsdk: null,\n\n        //for making multiple instances\n        clone: function () {\n            return $.extend(true, {}, this);\n        },\n\n        init: function(mstoken, msregion, mslanguage, referencetext) {\n            var that = this;\n            this.thetoken = mstoken;\n            this.theregion = msregion;\n            this.thelanguage = mslanguage;\n            this.thereferencetext = referencetext;\n            log.debug('MS Speech init');\n            if(!window.hasOwnProperty('SpeechSDK')){ \n                log.debug('MS Speech loading');\n                $.getScript('https://aka.ms/csspeech/jsbrowserpackageraw', function(){\n                    log.debug('MS Speech loaded');\n                    that.speechsdk = window.SpeechSDK;\n                    log.debug(that.speechsdk);\n                });\n            }\n\n            //this.speechsdk = require('microsoft-speech-browser-sdk');\n        },\n\n        recognize: function(blob, callback) {\n            var that = this;\n            \n          //MS Speech SDK requires the audio to be in wav format and to have a name field\n          blob.name = 'audio.wav';\n          let audioConfig = that.speechsdk.AudioConfig.fromWavFileInput(blob,blob.name);\n\n          var speechConfig = that.speechsdk.SpeechConfig.fromAuthorizationToken(that.thetoken, that.theregion);\n          speechConfig.speechRecognitionLanguage = that.thelanguage;\n\n          //need to pass this in, better\n          var referencetext = that.thereferencetext;\n\n          // create pronunciation assessment config, set grading system, granularity and if enable miscue based on your requirement.\n          const pronunciationAssessmentConfig = new that.speechsdk.PronunciationAssessmentConfig(\n              referencetext,\n              that.speechsdk.PronunciationAssessmentGradingSystem.HundredMark,\n              that.speechsdk.PronunciationAssessmentGranularity.Phoneme,\n              true\n          );\n          pronunciationAssessmentConfig.enableProsodyAssessment = true;\n\n          // create the speech recognizer.\n          var reco = new that.speechsdk.SpeechRecognizer(speechConfig, audioConfig);\n          // (Optional) get the session ID\n          reco.sessionStarted = (_s, e) => {\n              console.log(`SESSION ID: ${e.sessionId}`);\n          };\n          pronunciationAssessmentConfig.applyTo(reco);\n\n          reco.recognizeOnceAsync(\n              function (speechRecognitionResult) {\n                    // The pronunciation assessment result as a Speech SDK object\n                    var pronunciationAssessmentResult = that.speechsdk.PronunciationAssessmentResult.fromResult(speechRecognitionResult);\n                    // The pronunciation assessment result as a JSON string\n                    //var pronunciationAssessmentResultJson = speechRecognitionResult.properties.getProperty(SpeechSDK.PropertyId.SpeechServiceResponse_JsonResult);\n                  callback(pronunciationAssessmentResult);\n              },\n              function (err) {\n                  console.log(\"ERROR: \" + err);\n                  exit();\n              }\n          );\n        },\n\n        on_recognition: function(){\n\n        },\n\n     }\n\n});"],"names":["define","$","log","debug","thetoken","theregion","thelanguage","thereferencetext","speechsdk","clone","extend","this","init","mstoken","msregion","mslanguage","referencetext","that","window","hasOwnProperty","getScript","SpeechSDK","recognize","blob","callback","name","audioConfig","AudioConfig","fromWavFileInput","speechConfig","SpeechConfig","fromAuthorizationToken","speechRecognitionLanguage","pronunciationAssessmentConfig","PronunciationAssessmentConfig","PronunciationAssessmentGradingSystem","HundredMark","PronunciationAssessmentGranularity","Phoneme","enableProsodyAssessment","reco","SpeechRecognizer","sessionStarted","_s","e","console","sessionId","applyTo","recognizeOnceAsync","speechRecognitionResult","pronunciationAssessmentResult","PronunciationAssessmentResult","fromResult","err","exit","on_recognition"],"mappings":"AAAAA,mCAAO,CAAC,SACJ,aACA,SAAUC,EAAGC,YAObA,IAAIC,MAAM,0BAEH,CAEHC,SAAU,KACVC,UAAW,KACXC,YAAa,KACbC,iBAAkB,KAClBC,UAAW,KAGXC,MAAO,kBACIR,EAAES,QAAO,EAAM,GAAIC,OAG9BC,KAAM,SAASC,QAASC,SAAUC,WAAYC,mBACtCC,KAAON,UACNP,SAAWS,aACXR,UAAYS,cACZR,YAAcS,gBACdR,iBAAmBS,cACxBd,IAAIC,MAAM,kBACNe,OAAOC,eAAe,eACtBjB,IAAIC,MAAM,qBACVF,EAAEmB,UAAU,+CAA+C,WACvDlB,IAAIC,MAAM,oBACVc,KAAKT,UAAYU,OAAOG,UACxBnB,IAAIC,MAAMc,KAAKT,gBAO3Bc,UAAW,SAASC,KAAMC,cAClBP,KAAON,KAGbY,KAAKE,KAAO,gBACRC,YAAcT,KAAKT,UAAUmB,YAAYC,iBAAiBL,KAAKA,KAAKE,UAEpEI,aAAeZ,KAAKT,UAAUsB,aAAaC,uBAAuBd,KAAKb,SAAUa,KAAKZ,WAC1FwB,aAAaG,0BAA4Bf,KAAKX,gBAG1CU,cAAgBC,KAAKV,uBAGnB0B,8BAAgC,IAAIhB,KAAKT,UAAU0B,8BACrDlB,cACAC,KAAKT,UAAU2B,qCAAqCC,YACpDnB,KAAKT,UAAU6B,mCAAmCC,SAClD,GAEJL,8BAA8BM,yBAA0B,MAGpDC,KAAO,IAAIvB,KAAKT,UAAUiC,iBAAiBZ,aAAcH,aAE7Dc,KAAKE,eAAiB,CAACC,GAAIC,KACvBC,QAAQ3C,0BAAmB0C,EAAEE,aAEjCb,8BAA8Bc,QAAQP,MAEtCA,KAAKQ,oBACD,SAAUC,6BAEAC,8BAAgCjC,KAAKT,UAAU2C,8BAA8BC,WAAWH,yBAG9FzB,SAAS0B,kCAEb,SAAUG,KACNR,QAAQ3C,IAAI,UAAYmD,KACxBC,WAKVC,eAAgB"}